# -*- coding: utf-8 -*-
"""Chapter1. 나의 첫 머신러닝.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sXHPC2fbQchRPIvOfomIDVgAj8sN8dMS

#01-1. 인공지능과 머신러닝, 딥러닝

**인공지능**: 사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술
<br> **머신러닝**: 규칙을 일일이 프로그래밍하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야 -> scikit-learn
<br> = 인공지능의 하위 분야 중 지능을 구현하기 위한 소프트웨어를 담당하는 핵심 분야
<br> **딥러닝**: 머신러닝 알고리즘 중 인공 신경망을 기반으로 한 방법을 통칭하여 부르는 것 -> Tensorflow, PyTorch

#01-2. 코랩과 주피터 노트북
"""

print('Hello World')

"""#01-3. 마켓과 머신러닝

생선 분류 문제 - 도미, 곤들매기, 농어, 강꼬치고기, 로치, 빙어, 송어
<br> 데이터셋: https://www.kaggle.com/aungpyaeap/fish-market
"""

import pandas as pd
fish_data = pd.read_csv('/content/drive/MyDrive/혼자공부하는머신러닝+딥러닝/Fish.csv')

# 도미의 길이와 무게
bream_length = fish_data[fish_data['Species'] == 'Bream']['Length2'].tolist()
bream_weight = fish_data[fish_data['Species'] == 'Bream']['Weight'].tolist()

# 산점도 그려보기
import matplotlib.pyplot as plt

plt.scatter(bream_length, bream_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
# 길이가 길수록 무게가 많이 나가는 선형적(linear) 그래프

fish_data[fish_data['Species'] == 'Smelt']

# 빙어의 길이와 무게
smelt_length = fish_data[fish_data['Species'] == 'Smelt']['Length2'].tolist()
smelt_weight = fish_data[fish_data['Species'] == 'Smelt']['Weight'].tolist()

plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()

# K-최근접 이웃 알고리즘을 이용해 도미와 빙어 데이터 구분
length = bream_length + smelt_length
weight = bream_weight + smelt_weight

# 사이킷런을 이용하기 위해 2차원 리스트(길이, 무게) 생성
fish_data = [[l, w] for l, w in zip(length, weight)]

fish_data

fish_target = [1] * 35 + [0] * 14 # 도미는 35번, 빙어는 14번 등장

from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()
kn.fit(fish_data, fish_target) # 주어진 데이터로 알고리즘을 훈련

kn.score(fish_data, fish_target) # 훈련 결과를 평가 - 정확도가 1

kn.predict([[30, 600]]) # 정답을 예측해 보기

"""### K-최근접 이웃 알고리즘
- 새로운 데이터에 대해 예측할 때는 가장 가까운 직선거리에 어떤 데이터가 있는지 살펴보기만 하면 됨
- 단점은, 데이터가 아주 많은 경우, 메모리가 많이 필요하고 직선거리를 계산하는 데 많은 시간이 필요하다는 것

### 사이킷런의 KNeighborsClassifier 클래스
- _fit_X 속성에 전달한 fish_data를 모두 가지고 있음
- _y 속성에 fish_target을 가지고 있음
- 즉, k-최근접 이웃 알고리즘은 무언가 훈련되는 것이 없음
<br> fit()메서드에 전달한 데이터를 모두 저장하고 있다가 새로운 데이터가 등장하면 가장 가까운 데이터를 참고하여 생선을 분류함
"""

kn._fit_X

kn._y

# 몇 개의 데이터를 참고하여 생선을 분류할 지는 정해줄 수 있음 - n_neighbors
kn49 = KNeighborsClassifier(n_neighbors=49) # 참고 데이터를 49개로 한 kn49 모델
kn49.fit(fish_data, fish_target)
kn49.score(fish_data, fish_target)

